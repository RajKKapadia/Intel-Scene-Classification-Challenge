{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Old_Top.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "TofVOu0VDVOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "9068fee8-92ff-43db-98cf-cff674c4cb36"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pzmNwDdNDswi",
        "colab_type": "code",
        "outputId": "ec1810ed-efaf-437d-b7ab-e3168d082212",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "print (\"Uncompressing zip file\")\n",
        "zip_ref = zipfile.ZipFile('/gdrive/My Drive/Colab Notebooks/'\n",
        "                          'Intell Scene Identification Challenge/train-scene classification.zip', 'r')\n",
        "zip_ref.extractall('train_scene_classification/')\n",
        "zip_ref.close()\n",
        "print(\"Finished\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uncompressing zip file\n",
            "Finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tXobX8NJMAMj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q h5py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGyrcp_u9kSj",
        "colab_type": "code",
        "outputId": "25ea9657-7456-4c9e-c684-ab4af1b334d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "from keras.utils import to_categorical, Sequence\n",
        "\n",
        "from keras.layers import (Dense, Flatten, Add, BatchNormalization,\n",
        "                          Conv2D, MaxPooling2D, AveragePooling2D,\n",
        "                          Input, Activation, Flatten, Dropout)\n",
        "\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.optimizers import Adadelta\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from sklearn.model_selection import RepeatedKFold"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "PrmKLNA79wT8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "IMAGES_PATH = \"train_scene_classification/train/\"\n",
        "\n",
        "train = pd.read_csv(\"train_scene_classification/train.csv\")\n",
        "\n",
        "test = pd.read_csv(\"/gdrive/My Drive/Colab Notebooks/\"\n",
        "                   \"Intell Scene Identification Challenge/test_WyRytb0.csv\")\n",
        "\n",
        "ids = train['image_name']\n",
        "labels = train['label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-QFO903D9Hy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "  \n",
        "  \"\"\" DataGenerator Class,\n",
        "      Generate images and labels on the go\n",
        "      Less memory\n",
        "      Fast\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, list_IDs, image_names, labels,\n",
        "               batch_size=64, width = 150, height=150,\n",
        "               num_channels=3, num_classes=6, shuffle=False):\n",
        "    \n",
        "    \"\"\" Initialize parameters,\n",
        "    \"\"\"\n",
        "    \n",
        "    self.list_IDs = list_IDs\n",
        "    self.image_names = image_names\n",
        "    self.labels = labels\n",
        "    self.batch_size = batch_size\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.num_channels = num_channels\n",
        "    self.num_classes = num_classes\n",
        "    self.shuffle = shuffle\n",
        "    self.on_epoch_end()\n",
        "    \n",
        "  def on_epoch_end(self):\n",
        "    \n",
        "    \"\"\" Updates indexes after each epoch\n",
        "    \"\"\"\n",
        "    \n",
        "    self.indexes = np.arange(len(self.list_IDs))\n",
        "    if self.shuffle == True:\n",
        "      np.random.shuffle(self.indexes)\n",
        "      \n",
        "  def get_input(self, ID):\n",
        "    \n",
        "    \"\"\" Read the image from the ID and return image\n",
        "    \"\"\"\n",
        "    \n",
        "    img = cv.imread(IMAGES_PATH+self.image_names[ID])\n",
        "    if img.shape[0] != self.width or img.shape[1] != self.height:\n",
        "      img = cv.resize(img, (self.width, self.height), interpolation = cv.INTER_CUBIC)\n",
        "    img = img / 255\n",
        "    return img\n",
        "      \n",
        "  def __data_generation(self, list_IDs_temp):\n",
        "    \n",
        "    \"\"\" Generates batch of X and y\n",
        "    \"\"\"\n",
        "    \n",
        "    X = np.zeros((self.batch_size, self.width, self.height, self.num_channels))\n",
        "    y = np.zeros((self.batch_size, self.num_classes))\n",
        "    \n",
        "    for i, ID in enumerate(list_IDs_temp):\n",
        "      \n",
        "      X[i,] = self.get_input(ID)\n",
        "      lbl = to_categorical(self.labels[ID], num_classes=self.num_classes)\n",
        "      y[i,] = lbl\n",
        "    return X, y  \n",
        "  \n",
        "  def __len__(self):\n",
        "    \n",
        "    \"\"\" Denotes the number of batches per epoch\n",
        "    \"\"\"\n",
        "    \n",
        "    return int(np.floor(len(self.list_IDs) / self.batch_size))\n",
        "  \n",
        "  def __getitem__(self, index):\n",
        "    \n",
        "    \"\"\" Generate one batch of data\n",
        "    \"\"\"\n",
        "    \n",
        "    indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "    list_IDs_temp = [self.list_IDs[k] for k in indexes]\n",
        "    X, y = self.__data_generation(list_IDs_temp)\n",
        "    return X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H14SF4_-DR23",
        "colab_type": "code",
        "outputId": "af30ba68-4eed-4078-d6fe-1cc582faa2cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1394
        }
      },
      "cell_type": "code",
      "source": [
        "input_img = Input(shape=(150, 150, 3))\n",
        "\n",
        "conv1 = Conv2D(16, kernel_size=(3,3), padding='same')(input_img)\n",
        "conv1 = Conv2D(16, kernel_size=(3,3), padding='same')(conv1)\n",
        "bn1 = BatchNormalization()(conv1)\n",
        "act1 = Activation('relu')(bn1)\n",
        "max_pool1 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(act1)\n",
        "\n",
        "conv2 = Conv2D(32, kernel_size=(3,3), padding='same')(max_pool1)\n",
        "conv2 = Conv2D(32, kernel_size=(3,3), padding='same')(conv2)\n",
        "bn2 = BatchNormalization()(conv2)\n",
        "act2 = Activation('relu')(bn2)\n",
        "max_pool2 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(act2)\n",
        "\n",
        "conv3 = Conv2D(64, kernel_size=(3,3), padding='same')(max_pool2)\n",
        "conv3 = Conv2D(64, kernel_size=(3,3), padding='same')(conv3)\n",
        "bn3 = BatchNormalization()(conv3)\n",
        "act3 = Activation('relu')(bn3)\n",
        "max_pool3 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(act3)\n",
        "\n",
        "conv4 = Conv2D(128, kernel_size=(3,3), padding='same')(max_pool3)\n",
        "conv4 = Conv2D(128, kernel_size=(3,3), padding='same')(conv4)\n",
        "bn4 = BatchNormalization()(conv4)\n",
        "act4 = Activation('relu')(bn4)\n",
        "max_pool4 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(act4)\n",
        "\n",
        "conv5 = Conv2D(256, kernel_size=(3,3), padding='same')(max_pool4)\n",
        "conv5 = Conv2D(256, kernel_size=(3,3), padding='same')(conv5)\n",
        "bn5 = BatchNormalization()(conv5)\n",
        "act5 = Activation('relu')(bn5)\n",
        "max_pool5 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(act5)\n",
        "\n",
        "conv6 = Conv2D(512, kernel_size=(3,3), padding='same')(max_pool5)\n",
        "conv6 = Conv2D(512, kernel_size=(3,3), padding='same')(conv6)\n",
        "bn6 = BatchNormalization()(conv6)\n",
        "act6 = Activation('relu')(bn6)\n",
        "max_pool6 = MaxPooling2D(pool_size=(2,2), strides=(2,2))(act6)\n",
        "\n",
        "flat = Flatten()(max_pool6)\n",
        "\n",
        "fc1 = Dense(700, activation='relu')(flat)\n",
        "drop1 = Dropout(0.25)(fc1)\n",
        "fc2 = Dense(700, activation='relu')(drop1)\n",
        "drop2 = Dropout(0.25)(fc2)\n",
        "\n",
        "output_label = Dense(6, activation='sigmoid')(drop2)\n",
        "\n",
        "model = Model(inputs=[input_img], outputs=[output_label])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 150, 150, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 150, 150, 16)      448       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 150, 150, 16)      2320      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 150, 150, 16)      64        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 150, 150, 16)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 75, 75, 32)        4640      \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 75, 75, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 75, 75, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 75, 75, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 37, 37, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 37, 37, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 37, 37, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 37, 37, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 37, 37, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 18, 18, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 18, 18, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 18, 18, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 18, 18, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 9, 9, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 9, 9, 256)         295168    \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 9, 9, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 9, 9, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 700)               1434300   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 700)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 700)               490700    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 700)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 6)                 4206      \n",
            "=================================================================\n",
            "Total params: 6,651,974\n",
            "Trainable params: 6,649,958\n",
            "Non-trainable params: 2,016\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5Ze3orCIED4K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "adadelta = Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
        "model.compile(optimizer=adadelta, loss='binary_crossentropy',\n",
        "              metrics=['categorical_accuracy', 'binary_accuracy'])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=5, min_lr=0.0001, verbose=1)\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=8,\n",
        "                               verbose=1, mode='auto')\n",
        "checkpointer = ModelCheckpoint(filepath='weights.{epoch:02d}-{val_loss:.3f}.hdf5',\n",
        "                               verbose=1, save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NaCjJw0Si84m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_ids = np.arange(0, len(ids))\n",
        "train_ids = all_ids[0:14600]\n",
        "validate_ids = all_ids[14600:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2hTdb8s9EiKN",
        "colab_type": "code",
        "outputId": "a47dbcf4-de51-42a9-878b-04485820290b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1822
        }
      },
      "cell_type": "code",
      "source": [
        "train_generator = DataGenerator(train_ids, ids, labels, batch_size=64)\n",
        "validate_generator = DataGenerator(validate_ids, ids, labels, batch_size=64)\n",
        "\n",
        "history = model.fit_generator(generator=train_generator, epochs=30,\n",
        "                                     verbose=1,\n",
        "                                     callbacks=[reduce_lr, early_stopping, checkpointer],\n",
        "                                     validation_data = validate_generator,\n",
        "                                     use_multiprocessing = True, workers=8)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "228/228 [==============================] - 73s 321ms/step - loss: 0.3200 - categorical_accuracy: 0.5578 - binary_accuracy: 0.8650 - val_loss: 0.6497 - val_categorical_accuracy: 0.4428 - val_binary_accuracy: 0.8215\n",
            "\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.64971, saving model to weights.01-0.650.hdf5\n",
            "Epoch 2/30\n",
            "228/228 [==============================] - 61s 268ms/step - loss: 0.2089 - categorical_accuracy: 0.7373 - binary_accuracy: 0.9142 - val_loss: 0.4065 - val_categorical_accuracy: 0.6542 - val_binary_accuracy: 0.8871\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.64971 to 0.40651, saving model to weights.02-0.407.hdf5\n",
            "Epoch 3/30\n",
            "228/228 [==============================] - 62s 272ms/step - loss: 0.1691 - categorical_accuracy: 0.7995 - binary_accuracy: 0.9344 - val_loss: 0.3175 - val_categorical_accuracy: 0.6419 - val_binary_accuracy: 0.8827\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.40651 to 0.31746, saving model to weights.03-0.317.hdf5\n",
            "Epoch 4/30\n",
            "228/228 [==============================] - 61s 269ms/step - loss: 0.1456 - categorical_accuracy: 0.8268 - binary_accuracy: 0.9428 - val_loss: 0.1848 - val_categorical_accuracy: 0.7718 - val_binary_accuracy: 0.9256\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.31746 to 0.18484, saving model to weights.04-0.185.hdf5\n",
            "Epoch 5/30\n",
            "228/228 [==============================] - 61s 268ms/step - loss: 0.1350 - categorical_accuracy: 0.8448 - binary_accuracy: 0.9488 - val_loss: 0.1496 - val_categorical_accuracy: 0.8376 - val_binary_accuracy: 0.9460\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.18484 to 0.14960, saving model to weights.05-0.150.hdf5\n",
            "Epoch 6/30\n",
            "228/228 [==============================] - 61s 269ms/step - loss: 0.1242 - categorical_accuracy: 0.8577 - binary_accuracy: 0.9532 - val_loss: 0.1690 - val_categorical_accuracy: 0.8010 - val_binary_accuracy: 0.9358\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.14960\n",
            "Epoch 7/30\n",
            "228/228 [==============================] - 62s 274ms/step - loss: 0.1171 - categorical_accuracy: 0.8636 - binary_accuracy: 0.9556 - val_loss: 0.2674 - val_categorical_accuracy: 0.6842 - val_binary_accuracy: 0.8975\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.14960\n",
            "Epoch 8/30\n",
            "227/228 [============================>.] - ETA: 0s - loss: 0.1100 - categorical_accuracy: 0.8731 - binary_accuracy: 0.9584\n",
            "Epoch 8/30\n",
            "228/228 [==============================] - 63s 276ms/step - loss: 0.1098 - categorical_accuracy: 0.8733 - binary_accuracy: 0.9584 - val_loss: 0.1833 - val_categorical_accuracy: 0.7833 - val_binary_accuracy: 0.9309\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.14960\n",
            "Epoch 9/30\n",
            "228/228 [==============================] - 62s 272ms/step - loss: 0.1020 - categorical_accuracy: 0.8837 - binary_accuracy: 0.9616 - val_loss: 0.2017 - val_categorical_accuracy: 0.7623 - val_binary_accuracy: 0.9237\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.14960\n",
            "Epoch 00009: val_loss did not improve from 0.14960\n",
            "Epoch 10/30\n",
            "228/228 [==============================] - 63s 275ms/step - loss: 0.0956 - categorical_accuracy: 0.8899 - binary_accuracy: 0.9640 - val_loss: 0.2691 - val_categorical_accuracy: 0.7833 - val_binary_accuracy: 0.9278\n",
            "\n",
            "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.1.\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.14960\n",
            "Epoch 11/30\n",
            "228/228 [==============================] - 61s 268ms/step - loss: 0.0687 - categorical_accuracy: 0.9230 - binary_accuracy: 0.9747 - val_loss: 0.0861 - val_categorical_accuracy: 0.8997 - val_binary_accuracy: 0.9668\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.14960 to 0.08606, saving model to weights.11-0.086.hdf5\n",
            "Epoch 12/30\n",
            "227/228 [============================>.] - ETA: 0s - loss: 0.0606 - categorical_accuracy: 0.9331 - binary_accuracy: 0.9780\n",
            "Epoch 00011: val_loss improved from 0.14960 to 0.08606, saving model to weights.11-0.086.hdf5\n",
            "228/228 [==============================] - 61s 268ms/step - loss: 0.0606 - categorical_accuracy: 0.9331 - binary_accuracy: 0.9781 - val_loss: 0.0899 - val_categorical_accuracy: 0.8976 - val_binary_accuracy: 0.9667\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.08606\n",
            "Epoch 13/30\n",
            "227/228 [============================>.] - ETA: 0s - loss: 0.0569 - categorical_accuracy: 0.9371 - binary_accuracy: 0.9795\n",
            "Epoch 00012: val_loss did not improve from 0.08606\n",
            "228/228 [==============================] - 62s 274ms/step - loss: 0.0571 - categorical_accuracy: 0.9369 - binary_accuracy: 0.9794 - val_loss: 0.0849 - val_categorical_accuracy: 0.9046 - val_binary_accuracy: 0.9684\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.08606 to 0.08492, saving model to weights.13-0.085.hdf5\n",
            "Epoch 14/30\n",
            "228/228 [==============================] - 61s 269ms/step - loss: 0.0539 - categorical_accuracy: 0.9409 - binary_accuracy: 0.9804 - val_loss: 0.0868 - val_categorical_accuracy: 0.9042 - val_binary_accuracy: 0.9684\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.08492\n",
            "Epoch 15/30\n",
            "228/228 [==============================] - 63s 275ms/step - loss: 0.0513 - categorical_accuracy: 0.9437 - binary_accuracy: 0.9816 - val_loss: 0.0906 - val_categorical_accuracy: 0.9025 - val_binary_accuracy: 0.9675\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.08492\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.08492\n",
            "Epoch 16/30\n",
            "227/228 [============================>.] - ETA: 0s - loss: 0.0486 - categorical_accuracy: 0.9471 - binary_accuracy: 0.9826\n",
            "Epoch 16/30\n",
            "228/228 [==============================] - 63s 277ms/step - loss: 0.0489 - categorical_accuracy: 0.9468 - binary_accuracy: 0.9826 - val_loss: 0.1004 - val_categorical_accuracy: 0.8947 - val_binary_accuracy: 0.9652\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.08492\n",
            "Epoch 17/30\n",
            "228/228 [==============================] - 63s 276ms/step - loss: 0.0462 - categorical_accuracy: 0.9507 - binary_accuracy: 0.9836 - val_loss: 0.0925 - val_categorical_accuracy: 0.9087 - val_binary_accuracy: 0.9692\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.08492\n",
            "Epoch 18/30\n",
            "228/228 [==============================] - 63s 277ms/step - loss: 0.0432 - categorical_accuracy: 0.9535 - binary_accuracy: 0.9849 - val_loss: 0.0951 - val_categorical_accuracy: 0.9038 - val_binary_accuracy: 0.9681\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.08492\n",
            "Epoch 19/30\n",
            "228/228 [==============================] - 63s 277ms/step - loss: 0.0387 - categorical_accuracy: 0.9589 - binary_accuracy: 0.9863 - val_loss: 0.0948 - val_categorical_accuracy: 0.9034 - val_binary_accuracy: 0.9683\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.08492\n",
            "Epoch 20/30\n",
            "228/228 [==============================] - 63s 275ms/step - loss: 0.0377 - categorical_accuracy: 0.9605 - binary_accuracy: 0.9870 - val_loss: 0.0952 - val_categorical_accuracy: 0.9046 - val_binary_accuracy: 0.9688\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.08492\n",
            "Epoch 21/30\n",
            "227/228 [============================>.] - ETA: 0s - loss: 0.0377 - categorical_accuracy: 0.9609 - binary_accuracy: 0.9870\n",
            "Epoch 00020: val_loss did not improve from 0.08492\n",
            "Epoch 21/30\n",
            "228/228 [==============================] - 63s 276ms/step - loss: 0.0377 - categorical_accuracy: 0.9609 - binary_accuracy: 0.9870 - val_loss: 0.0951 - val_categorical_accuracy: 0.9054 - val_binary_accuracy: 0.9691\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.08492\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GaqIBVWaPbOc",
        "colab_type": "code",
        "outputId": "681f8d60-675e-4881-997f-6170b7766895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t    weights.02-0.407.hdf5  weights.05-0.150.hdf5\n",
            "train_scene_classification  weights.03-0.317.hdf5  weights.11-0.086.hdf5\n",
            "weights.01-0.650.hdf5\t    weights.04-0.185.hdf5  weights.13-0.085.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VBP3jjGYPe2t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(\"weights.13-0.085.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nIesTTyaEkxi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_ids = test['image_name']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ht9T_QlVNx-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = np.zeros((len(test_ids), 6))\n",
        "\n",
        "for i, ID in enumerate(test_ids):\n",
        "\n",
        "  img = np.zeros((1, 150, 150, 3))\n",
        "  img_temp = cv.imread(IMAGES_PATH+ID)\n",
        "  if img_temp.shape[0] != 150 or img_temp.shape[1] != 150:\n",
        "    img_temp = cv.resize(img_temp, (150, 150), interpolation = cv.INTER_CUBIC)\n",
        "  img[0,] = img_temp/255\n",
        "  y_pred[i,] = model.predict(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aOq-9tmCOEtF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_sub = np.zeros((len(test_ids)), dtype=np.int8)\n",
        "\n",
        "for i, lbl in enumerate(y_pred):\n",
        "  \n",
        "  y_sub[i] = np.argmax(lbl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RCwPQPIlTpnd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "submission = pd.DataFrame({'image_name':test_ids,\n",
        "                           'label':y_sub})\n",
        "submission.to_csv('submission_two.csv', index=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6ponhmo8WUTs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('submission_two.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ODe7miqtWeqP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}